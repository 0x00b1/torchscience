{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Value Problem Solvers\n",
    "\n",
    "This notebook demonstrates `torchscience.integration.initial_value_problem` - differentiable ODE solvers for PyTorch.\n",
    "\n",
    "We'll explore three physics examples:\n",
    "1. **Double Pendulum** - chaotic dynamics with adaptive stepping\n",
    "2. **Lotka-Volterra** - ecology model with TensorDict state\n",
    "3. **Neural ODE** - learning dynamics with adjoint gradients\n",
    "\n",
    "Each example showcases different solver capabilities with interactive Plotly visualizations and Manim animations."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px  # noqa: F401\n",
    "import plotly.graph_objects as go  # noqa: F401\n",
    "import torch  # noqa: F401\n",
    "from plotly.subplots import make_subplots  # noqa: F401\n",
    "from tensordict import TensorDict  # noqa: F401\n",
    "\n",
    "try:\n",
    "    from manim import *  # noqa: F401, F403\n",
    "\n",
    "    MANIM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    MANIM_AVAILABLE = False\n",
    "    print(\"Note: manim not installed. Animation examples will be skipped.\")\n",
    "from IPython.display import Video  # noqa: F401\n",
    "\n",
    "from torchscience.integration.initial_value_problem import (  # noqa: F401\n",
    "    adjoint,\n",
    "    backward_euler,\n",
    "    dormand_prince_5,\n",
    "    euler,\n",
    "    midpoint,\n",
    "    runge_kutta_4,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Plotly defaults for dark theme\n",
    "plotly_template = \"plotly_dark\"  # noqa: F841"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Double Pendulum: Chaos and Adaptive Stepping\n",
    "\n",
    "The double pendulum is a classic chaotic system - two rigid rods connected at joints, swinging under gravity. Small changes in initial conditions lead to dramatically different trajectories.\n",
    "\n",
    "**State vector:** `[theta1, theta2, omega1, omega2]`\n",
    "- `theta1`, `theta2`: angles from vertical\n",
    "- `omega1`, `omega2`: angular velocities\n",
    "\n",
    "**Why it's a good test case:**\n",
    "- Chaotic dynamics require adaptive step sizes\n",
    "- Large state changes stress error estimation\n",
    "- Visually dramatic for demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_pendulum_dynamics(t, state):\n",
    "    \"\"\"\n",
    "    Double pendulum equations of motion.\n",
    "\n",
    "    Parameters:\n",
    "        t: time (unused, system is autonomous)\n",
    "        state: [theta1, theta2, omega1, omega2]\n",
    "\n",
    "    Returns:\n",
    "        [dtheta1/dt, dtheta2/dt, domega1/dt, domega2/dt]\n",
    "    \"\"\"\n",
    "    # Physical parameters\n",
    "    g = 9.81  # gravity\n",
    "    L1 = 1.0  # length of rod 1\n",
    "    L2 = 1.0  # length of rod 2\n",
    "    m1 = 1.0  # mass 1\n",
    "    m2 = 1.0  # mass 2\n",
    "\n",
    "    theta1, theta2, omega1, omega2 = (\n",
    "        state[..., 0],\n",
    "        state[..., 1],\n",
    "        state[..., 2],\n",
    "        state[..., 3],\n",
    "    )\n",
    "\n",
    "    delta = theta2 - theta1\n",
    "\n",
    "    # Denominator terms\n",
    "    den1 = (m1 + m2) * L1 - m2 * L1 * torch.cos(delta) ** 2\n",
    "    den2 = (L2 / L1) * den1\n",
    "\n",
    "    # Angular accelerations\n",
    "    domega1 = (\n",
    "        -m2 * L1 * omega1**2 * torch.sin(delta) * torch.cos(delta)\n",
    "        + m2 * g * torch.sin(theta2) * torch.cos(delta)\n",
    "        + m2 * L2 * omega2**2 * torch.sin(delta)\n",
    "        - (m1 + m2) * g * torch.sin(theta1)\n",
    "    ) / den1\n",
    "\n",
    "    domega2 = (\n",
    "        +m2 * L2 * omega2**2 * torch.sin(delta) * torch.cos(delta)\n",
    "        + (m1 + m2) * g * torch.sin(theta1) * torch.cos(delta)\n",
    "        + (m1 + m2) * L1 * omega1**2 * torch.sin(delta)\n",
    "        - (m1 + m2) * g * torch.sin(theta2)\n",
    "    ) / den2\n",
    "\n",
    "    return torch.stack([omega1, omega2, domega1, domega2], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Initial conditions: moderate angles for chaotic but tractable dynamics\n",
    "# [theta1, theta2, omega1, omega2]\n",
    "# Starting at ~120 degrees (2.1 rad) shows chaotic behavior without\n",
    "# the extreme step requirements of nearly inverted pendulums.\n",
    "y0 = torch.tensor([2.1, 2.5, 0.5, 0.0], dtype=torch.float64, device=device)\n",
    "\n",
    "# Solve with dormand_prince_5\n",
    "start = time.perf_counter()\n",
    "y_final, interp = dormand_prince_5(\n",
    "    double_pendulum_dynamics,\n",
    "    y0,\n",
    "    t_span=(0.0, 15.0),\n",
    "    rtol=1e-6,\n",
    "    atol=1e-8,\n",
    "    max_steps=50000,\n",
    ")\n",
    "elapsed = time.perf_counter() - start\n",
    "\n",
    "print(f\"Integration completed in {elapsed:.3f}s\")\n",
    "print(f\"Number of steps: {interp.n_steps}\")\n",
    "print(f\"Final state: theta1={y_final[0]:.3f}, theta2={y_final[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dense trajectory using interpolant\n",
    "t_dense = torch.linspace(0, 15, 1500, dtype=torch.float64, device=device)\n",
    "trajectory = interp(t_dense)\n",
    "\n",
    "theta1 = trajectory[:, 0].cpu().numpy()\n",
    "theta2 = trajectory[:, 1].cpu().numpy()\n",
    "omega1 = trajectory[:, 2].cpu().numpy()\n",
    "omega2 = trajectory[:, 3].cpu().numpy()\n",
    "t_np = t_dense.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D trajectory: (theta1, theta2, t) colored by omega1\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter3d(\n",
    "            x=theta1,\n",
    "            y=theta2,\n",
    "            z=t_np,\n",
    "            mode=\"lines\",\n",
    "            line=dict(\n",
    "                color=omega1,\n",
    "                colorscale=\"Viridis\",\n",
    "                width=2,\n",
    "                colorbar=dict(title=\"omega1\"),\n",
    "            ),\n",
    "            name=\"Trajectory\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Double Pendulum: Chaotic Trajectory\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"theta1 (rad)\",\n",
    "        yaxis_title=\"theta2 (rad)\",\n",
    "        zaxis_title=\"time (s)\",\n",
    "    ),\n",
    "    template=plotly_template,\n",
    "    width=800,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase portrait: (theta1, omega1) colored by time\n",
    "# Use markers mode for color mapping along the trajectory\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=theta1,\n",
    "            y=omega1,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                color=t_np,\n",
    "                colorscale=\"Plasma\",\n",
    "                size=2,\n",
    "                colorbar=dict(title=\"time (s)\"),\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Phase Portrait: theta1 vs omega1\",\n",
    "    xaxis_title=\"theta1 (rad)\",\n",
    "    yaxis_title=\"omega1 (rad/s)\",\n",
    "    template=plotly_template,\n",
    "    width=700,\n",
    "    height=500,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert angles to Cartesian coordinates\n",
    "L1, L2 = 1.0, 1.0\n",
    "\n",
    "x1 = L1 * np.sin(theta1)\n",
    "y1 = -L1 * np.cos(theta1)\n",
    "x2 = x1 + L2 * np.sin(theta2)\n",
    "y2 = y1 - L2 * np.cos(theta2)\n",
    "\n",
    "print(\n",
    "    f\"Mass 1 range: x=[{x1.min():.2f}, {x1.max():.2f}], y=[{y1.min():.2f}, {y1.max():.2f}]\"\n",
    ")\n",
    "print(\n",
    "    f\"Mass 2 range: x=[{x2.min():.2f}, {x2.max():.2f}], y=[{y2.min():.2f}, {y2.max():.2f}]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double pendulum animation (requires manim)\n",
    "if MANIM_AVAILABLE:\n",
    "    from manim import (\n",
    "        BLUE,\n",
    "        ORIGIN,\n",
    "        RED,\n",
    "        WHITE,\n",
    "        YELLOW,\n",
    "        Dot,\n",
    "        Line,\n",
    "        Scene,\n",
    "        TracedPath,\n",
    "    )\n",
    "\n",
    "    class DoublePendulumScene(Scene):\n",
    "        def construct(self):\n",
    "            # Physical parameters\n",
    "            L1, L2 = 2.0, 2.0  # Scaled for visibility\n",
    "\n",
    "            # Get trajectory data (use global variables from previous cells)\n",
    "            # Sample every 10th point for smoother animation\n",
    "            theta1_anim = theta1[::10]\n",
    "            theta2_anim = theta2[::10]\n",
    "\n",
    "            # Create pendulum components\n",
    "            pivot = Dot(ORIGIN, color=WHITE)\n",
    "\n",
    "            def get_positions(i):\n",
    "                t1, t2 = theta1_anim[i], theta2_anim[i]\n",
    "                p1 = np.array([L1 * np.sin(t1), -L1 * np.cos(t1), 0])\n",
    "                p2 = p1 + np.array([L2 * np.sin(t2), -L2 * np.cos(t2), 0])\n",
    "                return p1, p2\n",
    "\n",
    "            p1_0, p2_0 = get_positions(0)\n",
    "\n",
    "            rod1 = Line(ORIGIN, p1_0, color=BLUE, stroke_width=4)\n",
    "            rod2 = Line(p1_0, p2_0, color=RED, stroke_width=4)\n",
    "            mass1 = Dot(p1_0, color=BLUE, radius=0.15)\n",
    "            mass2 = Dot(p2_0, color=RED, radius=0.15)\n",
    "\n",
    "            # Trail for mass2\n",
    "            trail = TracedPath(\n",
    "                mass2.get_center,\n",
    "                stroke_color=YELLOW,\n",
    "                stroke_width=1,\n",
    "                stroke_opacity=0.5,\n",
    "            )\n",
    "\n",
    "            self.add(pivot, rod1, rod2, mass1, mass2, trail)\n",
    "\n",
    "            # This defines the scene - to render, use: manim -pql notebook.py DoublePendulumScene\n",
    "            # Or in a Jupyter cell with manim kernel: %%manim -qm DoublePendulumScene\n",
    "            self.wait(2)\n",
    "else:\n",
    "    print(\"Manim not available - skipping animation cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- **Adaptive Stepping:** Notice how `dormand_prince_5` takes many small steps during rapid changes and larger steps during calmer periods.\n",
    "- **Step Count:** The solver efficiently handles the chaotic dynamics with automatic step size adaptation.\n",
    "- **Sensitivity:** Try changing initial conditions by 0.01 rad - the trajectories diverge dramatically within seconds.\n",
    "- **Dense Output:** The interpolant provides smooth trajectories at any time point without re-solving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lotka-Volterra: TensorDict and Solver Comparison\n",
    "\n",
    "The Lotka-Volterra equations model predator-prey dynamics in ecology. Populations oscillate in closed orbits - when prey is abundant, predators thrive; as prey declines, predators starve.\n",
    "\n",
    "**Equations:**\n",
    "- `dx/dt = alpha*x - beta*x*y` (prey growth minus predation)\n",
    "- `dy/dt = delta*x*y - gamma*y` (predator growth minus death)\n",
    "\n",
    "**Why it's a good test case:**\n",
    "- Simple, intuitive dynamics\n",
    "- Closed orbits test energy conservation\n",
    "- TensorDict state demonstrates structured data handling\n",
    "- Smooth enough for fixed-step solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lotka_volterra(t, state):\n",
    "    \"\"\"\n",
    "    Lotka-Volterra predator-prey dynamics using TensorDict.\n",
    "\n",
    "    Parameters:\n",
    "        t: time (unused, system is autonomous)\n",
    "        state: TensorDict with 'prey' and 'predator' keys\n",
    "\n",
    "    Returns:\n",
    "        TensorDict with derivatives\n",
    "    \"\"\"\n",
    "    # Parameters\n",
    "    alpha = 1.0  # prey growth rate\n",
    "    beta = 0.1  # predation rate\n",
    "    delta = 0.075  # predator growth rate\n",
    "    gamma = 1.5  # predator death rate\n",
    "\n",
    "    x = state[\"prey\"]  # prey population\n",
    "    y = state[\"predator\"]  # predator population\n",
    "\n",
    "    dx = alpha * x - beta * x * y\n",
    "    dy = delta * x * y - gamma * y\n",
    "\n",
    "    return TensorDict(\n",
    "        {\n",
    "            \"prey\": dx,\n",
    "            \"predator\": dy,\n",
    "        },\n",
    "        batch_size=state.batch_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial populations\n",
    "state0 = TensorDict(\n",
    "    {\n",
    "        \"prey\": torch.tensor([40.0], device=device),\n",
    "        \"predator\": torch.tensor([9.0], device=device),\n",
    "    },\n",
    "    batch_size=[],\n",
    ")\n",
    "\n",
    "# Solve with runge_kutta_4 (fixed step, good for smooth problems)\n",
    "state_final, interp_lv = runge_kutta_4(\n",
    "    lotka_volterra,\n",
    "    state0,\n",
    "    t_span=(0.0, 50.0),\n",
    "    dt=0.01,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Initial: prey={state0['prey'].item():.1f}, predator={state0['predator'].item():.1f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Final:   prey={state_final['prey'].item():.1f}, predator={state_final['predator'].item():.1f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare solvers on Lotka-Volterra\n",
    "solvers = {\n",
    "    \"euler\": (euler, {\"dt\": 0.01}),\n",
    "    \"midpoint\": (midpoint, {\"dt\": 0.05}),\n",
    "    \"runge_kutta_4\": (runge_kutta_4, {\"dt\": 0.1}),\n",
    "    \"dormand_prince_5\": (dormand_prince_5, {}),\n",
    "}\n",
    "\n",
    "# Reference solution with tight tolerances\n",
    "state_ref, _ = dormand_prince_5(\n",
    "    lotka_volterra, state0, t_span=(0.0, 50.0), rtol=1e-6, atol=1e-8\n",
    ")\n",
    "\n",
    "results = {}\n",
    "interpolants = {}  # Store interpolants for cell 16\n",
    "for name, (solver, kwargs) in solvers.items():\n",
    "    start = time.perf_counter()\n",
    "    state_final, interp = solver(\n",
    "        lotka_volterra, state0, t_span=(0.0, 50.0), **kwargs\n",
    "    )\n",
    "    elapsed = time.perf_counter() - start\n",
    "\n",
    "    error = torch.sqrt(\n",
    "        (state_final[\"prey\"] - state_ref[\"prey\"]) ** 2\n",
    "        + (state_final[\"predator\"] - state_ref[\"predator\"]) ** 2\n",
    "    ).item()\n",
    "\n",
    "    results[name] = {\n",
    "        \"time\": elapsed,\n",
    "        \"error\": error,\n",
    "        \"prey_final\": state_final[\"prey\"].item(),\n",
    "        \"predator_final\": state_final[\"predator\"].item(),\n",
    "    }\n",
    "    interpolants[name] = interp  # Store interpolant\n",
    "\n",
    "# Display comparison\n",
    "print(\n",
    "    f\"{'Solver':<20} {'Time (s)':<12} {'Error':<12} {'Prey Final':<12} {'Predator Final':<12}\"\n",
    ")\n",
    "print(\"-\" * 68)\n",
    "for name, res in results.items():\n",
    "    print(\n",
    "        f\"{name:<20} {res['time']:<12.4f} {res['error']:<12.6f} {res['prey_final']:<12.2f} {res['predator_final']:<12.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series comparison\n",
    "t_eval = torch.linspace(0, 50, 500, device=device)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    subplot_titles=(\"Prey Population\", \"Predator Population\"),\n",
    ")\n",
    "\n",
    "colors = {\n",
    "    \"euler\": \"red\",\n",
    "    \"midpoint\": \"orange\",\n",
    "    \"runge_kutta_4\": \"green\",\n",
    "    \"dormand_prince_5\": \"blue\",\n",
    "}\n",
    "\n",
    "for name in solvers.keys():\n",
    "    interp = interpolants[name]  # Reuse stored interpolant\n",
    "\n",
    "    # Batched query - much faster\n",
    "    states = interp(t_eval)\n",
    "    # Handle both TensorDict and tensor return types\n",
    "    if hasattr(states, \"keys\"):  # TensorDict\n",
    "        prey_traj = states[\"prey\"].squeeze().cpu().numpy()\n",
    "        pred_traj = states[\"predator\"].squeeze().cpu().numpy()\n",
    "    else:\n",
    "        prey_traj = states[..., 0].cpu().numpy()\n",
    "        pred_traj = states[..., 1].cpu().numpy()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t_eval.cpu().numpy(),\n",
    "            y=prey_traj,\n",
    "            name=name,\n",
    "            line=dict(color=colors[name]),\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=t_eval.cpu().numpy(),\n",
    "            y=pred_traj,\n",
    "            name=name,\n",
    "            line=dict(color=colors[name]),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=2,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Solver Comparison: Lotka-Volterra\",\n",
    "    template=plotly_template,\n",
    "    height=600,\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Time\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Prey\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Predator\", row=2, col=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase portrait with multiple initial conditions\n",
    "fig = go.Figure()\n",
    "\n",
    "# Multiple initial conditions\n",
    "initial_conditions = [\n",
    "    (40.0, 9.0),\n",
    "    (50.0, 5.0),\n",
    "    (30.0, 12.0),\n",
    "    (60.0, 8.0),\n",
    "]\n",
    "\n",
    "t_eval_phase = torch.linspace(0, 30, 300, device=device)\n",
    "\n",
    "for x0, y0 in initial_conditions:\n",
    "    state_ic = TensorDict(\n",
    "        {\n",
    "            \"prey\": torch.tensor([x0], device=device),\n",
    "            \"predator\": torch.tensor([y0], device=device),\n",
    "        },\n",
    "        batch_size=[],\n",
    "    )\n",
    "\n",
    "    _, interp = runge_kutta_4(\n",
    "        lotka_volterra, state_ic, t_span=(0.0, 30.0), dt=0.05\n",
    "    )\n",
    "\n",
    "    # Batched query for efficiency\n",
    "    states = interp(t_eval_phase)\n",
    "    if hasattr(states, \"keys\"):  # TensorDict\n",
    "        prey_traj = states[\"prey\"].squeeze().cpu().numpy()\n",
    "        pred_traj = states[\"predator\"].squeeze().cpu().numpy()\n",
    "    else:\n",
    "        prey_traj = states[..., 0].cpu().numpy()\n",
    "        pred_traj = states[..., 1].cpu().numpy()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=prey_traj,\n",
    "            y=pred_traj,\n",
    "            mode=\"lines\",\n",
    "            name=f\"IC: ({x0}, {y0})\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Mark initial point\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[x0],\n",
    "            y=[y0],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=10, symbol=\"circle\"),\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Lotka-Volterra Phase Portrait\",\n",
    "    xaxis_title=\"Prey Population\",\n",
    "    yaxis_title=\"Predator Population\",\n",
    "    template=plotly_template,\n",
    "    width=700,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lotka-Volterra animation (requires manim)\n",
    "if MANIM_AVAILABLE:\n",
    "    from manim import (\n",
    "        DOWN,\n",
    "        GREEN,\n",
    "        LEFT,\n",
    "        RED,\n",
    "        RIGHT,\n",
    "        YELLOW,\n",
    "        Axes,\n",
    "        Dot,\n",
    "        Rectangle,\n",
    "        Scene,\n",
    "        Text,\n",
    "        VGroup,\n",
    "    )\n",
    "\n",
    "    class LotkaVolterraScene(Scene):\n",
    "        \"\"\"\n",
    "        Static scene template demonstrating Lotka-Volterra visualization layout.\n",
    "\n",
    "        This scene shows the basic structure. For full animation:\n",
    "        1. Extract this class to a .py file\n",
    "        2. Import trajectory data (prey_traj, pred_traj from cell 17)\n",
    "        3. Use self.play() with UpdateFromAlphaFunc to animate bars and dot\n",
    "\n",
    "        Render with: manim -pql script.py LotkaVolterraScene\n",
    "        \"\"\"\n",
    "\n",
    "        def construct(self):\n",
    "            # Two-panel layout: populations on left, phase portrait on right\n",
    "\n",
    "            # Left panel: population bars (scaled to approximate population values)\n",
    "            left_panel = VGroup()\n",
    "            # Scale: width = population / 20 for visibility\n",
    "            prey_bar = Rectangle(\n",
    "                height=0.3, width=2.0, color=GREEN, fill_opacity=0.8\n",
    "            )  # prey ~ 40\n",
    "            pred_bar = Rectangle(\n",
    "                height=0.3, width=0.45, color=RED, fill_opacity=0.8\n",
    "            )  # predator ~ 9\n",
    "            prey_label = Text(\"Prey: 40\", font_size=18).next_to(prey_bar, LEFT)\n",
    "            pred_label = Text(\"Pred: 9\", font_size=18).next_to(pred_bar, LEFT)\n",
    "\n",
    "            left_panel.add(\n",
    "                VGroup(prey_label, prey_bar).arrange(RIGHT, buff=0.3)\n",
    "            )\n",
    "            left_panel.add(\n",
    "                VGroup(pred_label, pred_bar).arrange(RIGHT, buff=0.3)\n",
    "            )\n",
    "            left_panel.arrange(DOWN, buff=0.5)\n",
    "            left_panel.to_edge(LEFT, buff=0.5)\n",
    "\n",
    "            # Right panel: phase portrait axes\n",
    "            axes = Axes(\n",
    "                x_range=[0, 80, 20],\n",
    "                y_range=[0, 30, 10],\n",
    "                x_length=5,\n",
    "                y_length=4,\n",
    "                tips=False,\n",
    "                axis_config={\"include_numbers\": True},\n",
    "            ).to_edge(RIGHT, buff=0.5)\n",
    "\n",
    "            axes_labels = axes.get_axis_labels(\n",
    "                x_label=\"Prey\", y_label=\"Predator\"\n",
    "            )\n",
    "\n",
    "            self.add(left_panel, axes, axes_labels)\n",
    "\n",
    "            # Initial point on phase portrait\n",
    "            dot = Dot(axes.c2p(40, 9), color=YELLOW, radius=0.1)\n",
    "            self.add(dot)\n",
    "\n",
    "            # Static display - to animate, use UpdateFromAlphaFunc\n",
    "            self.wait(2)\n",
    "else:\n",
    "    print(\"Manim not available - skipping Lotka-Volterra animation cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "- **TensorDict State:** Using named fields (`prey`, `predator`) makes the code self-documenting and prevents indexing errors.\n",
    "- **Closed Orbits:** The phase portraits show closed curves - a conserved quantity (related to the Hamiltonian) is preserved.\n",
    "- **Solver Selection:** For smooth problems like this, `runge_kutta_4` with moderate step size is efficient. Adaptive `dormand_prince_5` works but adds overhead.\n",
    "- **Error Accumulation:** Lower-order methods (Euler) accumulate phase error over long integrations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Neural ODE: Differentiable Dynamics and Adjoint Method\n",
    "\n",
    "Neural ODEs replace discrete layers with continuous transformations. Instead of:\n",
    "```\n",
    "h1 = f1(h0)\n",
    "h2 = f2(h1)\n",
    "...\n",
    "```\n",
    "\n",
    "We have:\n",
    "```\n",
    "h(t) = h(0) + integral_0^T f(h(t), t; theta) dt\n",
    "```\n",
    "\n",
    "**Key benefits:**\n",
    "- Continuous-depth models\n",
    "- Memory-efficient gradients via adjoint method\n",
    "- Invertible by design (for normalizing flows)\n",
    "\n",
    "**This example:** Classify points from two interleaved spirals using learned continuous dynamics.\n",
    "\n",
    "**Important insight:** In 2D, ODE trajectories cannot cross (uniqueness theorem), which limits expressiveness for non-linearly separable data. We address this using an **augmented state space** - lifting the 2D input to a higher-dimensional space where the dynamics can separate the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spirals(n_points=200, noise=0.1):\n",
    "    \"\"\"Generate two interleaved spiral datasets.\"\"\"\n",
    "    n = n_points // 2\n",
    "\n",
    "    # Spiral 1\n",
    "    theta1 = torch.linspace(0, 3 * np.pi, n)\n",
    "    r1 = theta1 / (3 * np.pi)\n",
    "    x1 = r1 * torch.cos(theta1) + noise * torch.randn(n)\n",
    "    y1 = r1 * torch.sin(theta1) + noise * torch.randn(n)\n",
    "\n",
    "    # Spiral 2 (rotated by pi)\n",
    "    theta2 = torch.linspace(0, 3 * np.pi, n)\n",
    "    r2 = theta2 / (3 * np.pi)\n",
    "    x2 = r2 * torch.cos(theta2 + np.pi) + noise * torch.randn(n)\n",
    "    y2 = r2 * torch.sin(theta2 + np.pi) + noise * torch.randn(n)\n",
    "\n",
    "    X = torch.stack([torch.cat([x1, x2]), torch.cat([y1, y2])], dim=1).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    y = torch.cat([torch.zeros(n), torch.ones(n)]).long().to(device)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = generate_spirals(400, noise=0.05)\n",
    "print(f\"Data shape: {X.shape}, Labels shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spiral data\n",
    "fig = go.Figure()\n",
    "\n",
    "for label, name, color in [(0, \"Spiral 1\", \"blue\"), (1, \"Spiral 2\", \"red\")]:\n",
    "    mask = y == label\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=X[mask, 0].cpu().numpy(),\n",
    "            y=X[mask, 1].cpu().numpy(),\n",
    "            mode=\"markers\",\n",
    "            name=name,\n",
    "            marker=dict(size=5, color=color, opacity=0.7),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Interleaved Spirals Dataset\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"y\",\n",
    "    template=plotly_template,\n",
    "    width=600,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ODEFunc(nn.Module):\n",
    "    \"\"\"Augmented state dynamics dh/dt = f(h, t) in higher-dimensional space.\"\"\"\n",
    "\n",
    "    def __init__(self, aug_dim=4, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(aug_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, aug_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, t, h):\n",
    "        \"\"\"Compute dh/dt. Note: t is unused (autonomous system).\"\"\"\n",
    "        return self.net(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural ODE classifier for 2D points.\n",
    "\n",
    "    Uses an augmented state space approach: the 2D input is first lifted\n",
    "    to a higher-dimensional space where the ODE dynamics can more easily\n",
    "    separate the classes (in 2D, ODE trajectories cannot cross, limiting\n",
    "    expressiveness for non-linearly separable data like spirals).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, aug_dim=4, hidden_dim=64, t_span=(0.0, 1.0)):\n",
    "        super().__init__()\n",
    "        self.aug_dim = aug_dim\n",
    "        # Lift 2D input to augmented state space\n",
    "        self.encoder = nn.Linear(2, aug_dim)\n",
    "        self.odefunc = ODEFunc(aug_dim, hidden_dim)\n",
    "        self.t_span = t_span\n",
    "        # Project augmented state to class logits\n",
    "        self.classifier = nn.Linear(aug_dim, 2)  # 2 classes\n",
    "\n",
    "        # Use direct backprop for training - gradients flow through ODE solver\n",
    "        # (adjoint method demonstrated separately in memory comparison)\n",
    "        self.solver = dormand_prince_5\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass: encode, integrate dynamics, then classify.\n",
    "\n",
    "        x: (batch, 2) input points\n",
    "        returns: (batch, 2) class logits\n",
    "        \"\"\"\n",
    "        # Lift to augmented state space\n",
    "        h0 = self.encoder(x)\n",
    "\n",
    "        # Integrate dynamics in augmented space\n",
    "        h_final, _ = self.solver(\n",
    "            self.odefunc,\n",
    "            h0,\n",
    "            t_span=self.t_span,\n",
    "            rtol=1e-3,\n",
    "            atol=1e-4,\n",
    "        )\n",
    "\n",
    "        # Classify final state\n",
    "        logits = self.classifier(h_final)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Instantiate model\n",
    "model = NeuralODE(aug_dim=4, hidden_dim=64).to(device)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 200\n",
    "batch_size = 64\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Shuffle data\n",
    "    perm = torch.randperm(len(X))\n",
    "    X_shuffled = X[perm]\n",
    "    y_shuffled = y[perm]\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        x_batch = X_shuffled[i : i + batch_size]\n",
    "        y_batch = y_shuffled[i : i + batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        acc = (preds == y).float().mean().item()\n",
    "\n",
    "    losses.append(epoch_loss / n_batches)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        print(f\"Epoch {epoch + 1:3d}: loss={losses[-1]:.4f}, acc={acc:.3f}\")\n",
    "\n",
    "print(f\"\\nFinal accuracy: {accuracies[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\"Loss\", \"Accuracy\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(y=losses, mode=\"lines\", name=\"Loss\", line=dict(color=\"red\")),\n",
    "    row=1,\n",
    "    col=1,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        y=accuracies, mode=\"lines\", name=\"Accuracy\", line=dict(color=\"green\")\n",
    "    ),\n",
    "    row=1,\n",
    "    col=2,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Neural ODE Training\",\n",
    "    template=plotly_template,\n",
    "    height=400,\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Epoch\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Epoch\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Loss\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Accuracy\", row=1, col=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision boundary visualization\n",
    "model.eval()\n",
    "\n",
    "# Create grid\n",
    "x_min, x_max = X[:, 0].min().item() - 0.5, X[:, 0].max().item() + 0.5\n",
    "y_min, y_max = X[:, 1].min().item() - 0.5, X[:, 1].max().item() + 0.5\n",
    "\n",
    "xx = torch.linspace(x_min, x_max, 100, device=device)\n",
    "yy = torch.linspace(y_min, y_max, 100, device=device)\n",
    "grid_x, grid_y = torch.meshgrid(xx, yy, indexing=\"xy\")\n",
    "grid_points = torch.stack([grid_x.flatten(), grid_y.flatten()], dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(grid_points)\n",
    "    probs = torch.softmax(logits, dim=1)[:, 1]  # P(class 1)\n",
    "    probs = probs.reshape(100, 100).cpu().numpy()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Decision boundary heatmap\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        x=xx.cpu().numpy(),\n",
    "        y=yy.cpu().numpy(),\n",
    "        z=probs.T,\n",
    "        colorscale=\"RdBu\",\n",
    "        opacity=0.5,\n",
    "        showscale=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Data points\n",
    "for label, name, color in [(0, \"Spiral 1\", \"blue\"), (1, \"Spiral 2\", \"red\")]:\n",
    "    mask = y == label\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=X[mask, 0].cpu().numpy(),\n",
    "            y=X[mask, 1].cpu().numpy(),\n",
    "            mode=\"markers\",\n",
    "            name=name,\n",
    "            marker=dict(\n",
    "                size=5, color=color, line=dict(width=0.5, color=\"white\")\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Neural ODE Decision Boundary\",\n",
    "    xaxis_title=\"x\",\n",
    "    yaxis_title=\"y\",\n",
    "    template=plotly_template,\n",
    "    width=700,\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory comparison: adjoint vs direct backprop\n",
    "import gc\n",
    "\n",
    "\n",
    "def count_grad_tensors():\n",
    "    \"\"\"Count tensors in autograd graph (approximation).\"\"\"\n",
    "    gc.collect()\n",
    "    return sum(\n",
    "        1\n",
    "        for obj in gc.get_objects()\n",
    "        if isinstance(obj, torch.Tensor) and obj.requires_grad\n",
    "    )\n",
    "\n",
    "\n",
    "# Direct backprop\n",
    "model_direct = NeuralODE(aug_dim=4, hidden_dim=64).to(device)\n",
    "model_direct.solver = dormand_prince_5  # No adjoint wrapper\n",
    "\n",
    "# Adjoint\n",
    "model_adjoint = NeuralODE(aug_dim=4, hidden_dim=64).to(device)\n",
    "model_adjoint.solver = adjoint(dormand_prince_5)\n",
    "\n",
    "# Set models to eval mode for consistent comparison\n",
    "model_direct.eval()\n",
    "model_adjoint.eval()\n",
    "\n",
    "x_test = X[:32]  # Small batch\n",
    "\n",
    "print(\"Memory comparison (gradient tensors created):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Direct\n",
    "gc.collect()\n",
    "base_count = count_grad_tensors()\n",
    "logits = model_direct(x_test)\n",
    "loss = logits.sum()\n",
    "loss.backward()\n",
    "direct_count = count_grad_tensors() - base_count\n",
    "print(f\"Direct backprop: ~{direct_count} tensors\")\n",
    "\n",
    "# Clear gradients before next comparison\n",
    "model_direct.zero_grad()\n",
    "\n",
    "# Adjoint\n",
    "gc.collect()\n",
    "base_count = count_grad_tensors()\n",
    "logits = model_adjoint(x_test)\n",
    "loss = logits.sum()\n",
    "loss.backward()\n",
    "adjoint_count = count_grad_tensors() - base_count\n",
    "print(f\"Adjoint method:  ~{adjoint_count} tensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "- **Adjoint Method:** Uses O(1) memory for autograd graph vs O(n_steps) for direct backprop. Essential for long integrations or large state dimensions.\n",
    "- **When to Use Adjoint:**\n",
    "  - Long integration times (100+ steps)\n",
    "  - Large state dimension\n",
    "  - Memory-constrained environments\n",
    "- **When NOT to Use Adjoint:**\n",
    "  - Short integrations (overhead not worth it)\n",
    "  - Need exact discretization gradients\n",
    "  - Differentiating through the interpolant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Solver Selection Guide\n",
    "\n",
    "| Solver | Order | Adaptive | Stiff | Best For |\n",
    "|--------|-------|----------|-------|----------|\n",
    "| `euler` | 1 | No | No | Education, quick prototypes |\n",
    "| `midpoint` | 2 | No | No | Smooth problems, better than Euler |\n",
    "| `runge_kutta_4` | 4 | No | No | Workhorse for non-stiff problems |\n",
    "| `dormand_prince_5` | 5(4) | Yes | No | Production-quality, error control |\n",
    "| `backward_euler` | 1 | No | Yes | Stiff problems (chemical kinetics, etc.) |\n",
    "\n",
    "**Wrappers:**\n",
    "- `adjoint(solver)` - Memory-efficient gradients via continuous adjoint method\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore more examples in the torchscience documentation\n",
    "- Check out normalizing flows for density estimation with Neural ODEs\n",
    "- See stiff ODE examples for chemical reaction networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
